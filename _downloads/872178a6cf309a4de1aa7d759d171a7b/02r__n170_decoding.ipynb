{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# N170 Decoding\n\nThis example runs a set of machine learning algorithms on the N170 faces/houses \ndataset, and compares them in terms of classification performance. \n\nThe data used is exactly the same as in the N170 `load_and_visualize` example. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Some standard pythonic imports\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os,numpy as np,pandas as pd\nfrom collections import OrderedDict\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\n# MNE functions\nfrom mne import Epochs,find_events\nfrom mne.decoding import Vectorizer\n\n# EEG-Notebooks functions\nfrom eegnb.analysis.analysis_utils import load_data\nfrom eegnb.datasets import fetch_dataset\n\n# Scikit-learn and Pyriemann ML functionalities\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.model_selection import cross_val_score, StratifiedShuffleSplit\nfrom pyriemann.estimation import ERPCovariances, XdawnCovariances\nfrom pyriemann.tangentspace import TangentSpace\nfrom pyriemann.classification import MDM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n\n( See the n170 `load_and_visualize` example for further description of this)\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "eegnb_data_path = os.path.join(os.path.expanduser('~/'),'.eegnb', 'data')    \nn170_data_path = os.path.join(eegnb_data_path, 'visual-N170', 'eegnb_examples')\n\n# If dataset hasn't been downloaded yet, download it \nif not os.path.isdir(n170_data_path):\n    fetch_dataset(data_dir=eegnb_data_path, experiment='visual-N170', site='eegnb_examples')        \n\nsubject = 1\nsession = 1\nraw = load_data(subject,session,\n                experiment='visual-N170', site='eegnb_examples', device_name='muse2016',\n                data_dir = eegnb_data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filteriing\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw.filter(1,30, method='iir')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Epoching\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create an array containing the timestamps and type of each stimulus (i.e. face or house)\nevents = find_events(raw)\nevent_id = {'House': 1, 'Face': 2}\n\n# Create an MNE Epochs object representing all the epochs around stimulus presentation\nepochs = Epochs(raw, events=events, event_id=event_id, \n                tmin=-0.1, tmax=0.8, baseline=None,\n                reject={'eeg': 75e-6}, preload=True,\n                verbose=False, picks=[0,1,2,3])\n\nprint('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\nepochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run classification\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clfs = OrderedDict()\nclfs['Vect + LR'] = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression())\nclfs['Vect + RegLDA'] = make_pipeline(Vectorizer(), LDA(shrinkage='auto', solver='eigen'))\nclfs['ERPCov + TS'] = make_pipeline(ERPCovariances(estimator='oas'), TangentSpace(), LogisticRegression())\nclfs['ERPCov + MDM'] = make_pipeline(ERPCovariances(estimator='oas'), MDM())\nclfs['XdawnCov + TS'] = make_pipeline(XdawnCovariances(estimator='oas'), TangentSpace(), LogisticRegression())\nclfs['XdawnCov + MDM'] = make_pipeline(XdawnCovariances(estimator='oas'), MDM())\n\n# format data\nepochs.pick_types(eeg=True)\nX = epochs.get_data() * 1e6\ntimes = epochs.times\ny = epochs.events[:, -1]\n\n# define cross validation \ncv = StratifiedShuffleSplit(n_splits=20, test_size=0.25, \n                                    random_state=42)\n\n# run cross validation for each pipeline\nauc = []\nmethods = []\nfor m in clfs:\n    print(m)\n    try:\n        res = cross_val_score(clfs[m], X, y==2, scoring='roc_auc', \n                              cv=cv, n_jobs=-1)\n        auc.extend(res)\n        methods.extend([m]*len(res))\n    except:\n        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Decoding Results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame(data=auc, columns=['AUC'])\nresults['Method'] = methods\n\nfig = plt.figure(figsize=[8,4])\nsns.barplot(data=results, x='AUC', y='Method')\nplt.xlim(0.4, 0.9)\nsns.despine()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}