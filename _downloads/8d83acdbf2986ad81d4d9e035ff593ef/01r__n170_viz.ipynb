{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# N170 Load and Visualize Data\n\nThis example demonstrates loading, organizing, and visualizing ERP response data from the visual P300 experiment. \n\nImages of cats and dogs are shown in a rapid serial visual presentation (RSVP) stream.\n\nThe data used is the first subject and first session of the one of the eeg-notebooks P300 example datasets, recorded using the InteraXon MUSE EEG headset (2016 model). \nThis session consists of six two-minute blocks of continuous recording.  \n\nWe first use the `fetch_datasets` to obtain a list of filenames. If these files are not already present \nin the specified data directory, they will be quickly downloaded from the cloud. \n\nAfter loading the data, we place it in an MNE `Epochs` object, and obtain the trial-averaged response. \n\nThe final figure plotted at the end shows the P300 response ERP waveform. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Some standard pythonic imports\nimport os\nfrom collections import OrderedDict\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# MNE functions\nfrom mne import Epochs,find_events\n\n# EEG-Notebooks functions\nfrom eegnb.analysis.utils import load_data,plot_conditions\nfrom eegnb.datasets import fetch_dataset\n\n# sphinx_gallery_thumbnail_number = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n\nWe will use the eeg-notebooks N170 example dataset\n\nNote that if you are running this locally, the following cell will download\nthe example dataset, if you do not already have it.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "eegnb_data_path = os.path.join(os.path.expanduser('~/'),'.eegnb', 'data')    \nn170_data_path = os.path.join(eegnb_data_path, 'visual-N170', 'eegnb_examples')\n\n# If dataset hasn't been downloaded yet, download it \nif not os.path.isdir(n170_data_path):\n    fetch_dataset(data_dir=eegnb_data_path, experiment='visual-N170', site='eegnb_examples');\n\nsubject = 1\nsession = 1\nraw = load_data(subject,session,\n                experiment='visual-N170', site='eegnb_examples', device_name='muse2016',\n                data_dir = eegnb_data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the power spectrum\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw.plot_psd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filtering\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw.filter(1,30, method='iir')\nraw.plot_psd(fmin=1, fmax=30);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Epoching\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create an array containing the timestamps and type of each stimulus (i.e. face or house)\nevents = find_events(raw)\nevent_id = {'House': 1, 'Face': 2}\n\n# Create an MNE Epochs object representing all the epochs around stimulus presentation\nepochs = Epochs(raw, events=events, event_id=event_id, \n                tmin=-0.1, tmax=0.8, baseline=None,\n                reject={'eeg': 75e-6}, preload=True, \n                verbose=False, picks=[0,1,2,3])\nprint('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\nepochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Epoch average\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "conditions = OrderedDict()\nconditions['House'] = [1]\nconditions['Face'] = [2]\n\nfig, ax = plot_conditions(epochs, conditions=conditions, \n                          ci=97.5, n_boot=1000, title='',\n                          diff_waveform=(1, 2))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}