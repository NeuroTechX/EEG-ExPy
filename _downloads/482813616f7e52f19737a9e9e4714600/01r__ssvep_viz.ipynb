{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nSSVEP Visualization\n===============================\n\nThis example demonstrates loading, organizing, and visualizing data from the steady-state visual evoked potentials (SSVEP) experiment. \n\nThe data used is the first subject and first session of the one of the eeg-notebooks ssvep example datasets, recorded using the InteraXon MUSE EEG headset (2016 model). This session consists of six two-minute blocks of continuous recording.  \n\nWe first use the `fetch_datasets` to obtain a list of filenames. If these files are not already present \nin the specified data directory, they will be quickly downloaded from the cloud. \n\nAfter loading the data, we place it in an MNE `Epochs` object, and obtain the trial-averaged response. \n\nThe final figures show the visual frequencies appearing in the measured power spectrum. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Some standard pythonic imports\nimport os, numpy as np, pandas as pd\nfrom collections import OrderedDict\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom matplotlib import pyplot as plt\n\n# MNE functions\nfrom mne import Epochs,find_events\nfrom mne.time_frequency import psd_welch,tfr_morlet\n\n# EEG-Notebooks functions\nfrom eegnb.analysis.utils import load_data,plot_conditions\nfrom eegnb.datasets import fetch_dataset\n\n# sphinx_gallery_thumbnail_number = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Data\n ---------------------\n\n We will use the eeg-notebooks SSVEP example dataset\n\n Note that if you are running this locally, the following cell will download\n the example dataset, if you do not already have it.\n\n##################################################################################################\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "eegnb_data_path = os.path.join(os.path.expanduser('~/'),'.eegnb', 'data')    \nssvep_data_path = os.path.join(eegnb_data_path, 'visual-SSVEP', 'eegnb_examples')\n\n# If dataset hasn't been downloaded yet, download it \nif not os.path.isdir(ssvep_data_path):\n    fetch_dataset(data_dir=eegnb_data_path, experiment='visual-SSVEP', site='eegnb_examples');        \n\n\nsubject = 1\nsession = 1\nraw = load_data(subject, session, \n                experiment='visual-SSVEP', site='eegnb_examples', device_name='muse2016',\n                data_dir = eegnb_data_path,\n                replace_ch_names={'Right AUX': 'POz'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the power spectrum\n----------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw.plot_psd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Epoching\n----------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Next, we will chunk (epoch) the data into segments representing the data 100ms before to 800ms after each stimulus.\n# Note: we will not reject epochs here because the amplitude of the SSVEP at POz is so large it is difficult to separate from eye blinks\n\nevents = find_events(raw)\nevent_id = {'30 Hz': 1, '20 Hz': 2}\nepochs = Epochs(raw, events=events, event_id=event_id, \n                tmin=-0.5, tmax=4, baseline=None, preload=True,\n                verbose=False, picks=[0, 1, 2, 3, 4])\nprint('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Stimuli-Specific PSD\n----------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Next, we can compare the PSD of epochs specifically during 20hz and 30hz stimulus presentation\n\nf, axs = plt.subplots(2, 1, figsize=(10, 10))\npsd1, freq1 = psd_welch(epochs['30 Hz'], n_fft=1028, n_per_seg=256 * 3, picks='all')\npsd2, freq2 = psd_welch(epochs['20 Hz'], n_fft=1028, n_per_seg=256 * 3, picks='all')\npsd1 = 10 * np.log10(psd1)\npsd2 = 10 * np.log10(psd2)\n\npsd1_mean = psd1.mean(0)\npsd1_std = psd1.mean(0)\n\npsd2_mean = psd2.mean(0)\npsd2_std = psd2.mean(0)\n\naxs[0].plot(freq1, psd1_mean[[0, 3], :].mean(0), color='b', label='30 Hz')\naxs[0].plot(freq2, psd2_mean[[0, 3], :].mean(0), color='r', label='20 Hz')\n\naxs[1].plot(freq1, psd1_mean[4, :], color='b', label='30 Hz')\naxs[1].plot(freq2, psd2_mean[4, :], color='r', label='20 Hz')\n\naxs[0].set_title('TP9 and TP10')\naxs[1].set_title('POz')\n\naxs[0].set_ylabel('Power Spectral Density (dB)')\naxs[1].set_ylabel('Power Spectral Density (dB)')\n\naxs[0].set_xlim((2, 50))\naxs[1].set_xlim((2, 50))\n\naxs[1].set_xlabel('Frequency (Hz)')\n\naxs[0].legend()\naxs[1].legend()\n\nplt.show();\n\n# With this visualization we can clearly see distinct peaks at 30hz and 20hz in the PSD, corresponding to the frequency of the visual stimulation. The peaks are much larger at the POz electrode, but still visible at TP9 and TP10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Spectrogram\n-----------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We can also look for SSVEPs in the spectrogram, which uses color to represent the power of frequencies in the EEG signal over time\n\nfrequencies = np.logspace(1, 1.75, 60)\ntfr, itc = tfr_morlet(epochs['30 Hz'], freqs=frequencies,picks='all',\n                              n_cycles=15, return_itc=True)\ntfr.plot(picks=[4], baseline=(-0.5, -0.1), mode='logratio', \n                 title='POz - 30 Hz stim');\n\ntfr, itc = tfr_morlet(epochs['20 Hz'], freqs=frequencies,picks='all',\n                              n_cycles=15, return_itc=True)\ntfr.plot(picks=[4], baseline=(-0.5, -0.1), mode='logratio', \n                 title='POz - 20 Hz stim');\n\nplt.tight_layout()\n\n# Once again we can see clear SSVEPs at 30hz and 20hz"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}