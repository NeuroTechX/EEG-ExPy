{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "P100 Load and Visualize Data\n",
    "===============================\n",
    "\n",
    "This example demonstrates loading, organizing, and visualizing EP response data from the visual P100 experiment. \n",
    "\n",
    "An animation of a checkerboard reversal is shown(the checkerboard squares' colours are toggled once each half a second).\n",
    "\n",
    "The data used is the first subject and first session of the one of the eeg-notebooks P100 example datasets.\n",
    "It was recorded using an OpenBCI Ultracortex EEG headset(Mark IV) with it's last five electrodes placed in the headset's\n",
    "node locations of (PO1, Oz, PO2, P3 and P4).\n",
    "These headset node locations were used to fit around a Meta Quest 2 headset, which tilted/angled the headset backwards\n",
    "so that the real locations of the electrodes are closer to the occipital lobe - O1, Iz, O2, PO1 and PO2.\n",
    "The session consisted of using the Meta Quest 2 linked with a PC to display the checkerboard reversal animation\n",
    "for thirty seconds of continuous recording.  \n",
    "\n",
    "We first use the `fetch_datasets` to obtain a list of filenames. If these files are not already present \n",
    "in the specified data directory, they will be quickly downloaded from the cloud. \n",
    "\n",
    "After loading the data from the occiptal channels, we place it in an MNE `Epochs` object, and then an `Evoked` object to obtain\n",
    "the trial-averaged delay of the response. \n",
    "\n",
    "The final figure plotted at the end shows the P100 response EP waveform. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "###################################################################################################\n",
    "# Setup\n",
    "# ---------------------\n",
    "\n",
    "# Some standard pythonic imports\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MNE functions\n",
    "from mne import Epochs,find_events,Evoked\n",
    "\n",
    "# EEG-Notebooks functions\n",
    "from eegnb.analysis.utils import load_data,plot_conditions\n",
    "from eegnb.datasets import fetch_dataset\n",
    "\n",
    "###################################################################################################\n",
    "# Load Data\n",
    "# ---------------------\n",
    "#\n",
    "# We will use the eeg-notebooks P100 example dataset\n",
    "#\n",
    "# Note that if you are running this locally, the following cell will download\n",
    "# the example dataset, if you do not already have it.\n",
    "#\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "eegnb_data_path = os.path.join(os.path.expanduser('~/'),'.eegnb', 'data')    \n",
    "experiment = 'visual_p100_both_eyes'\n",
    "p100_data_path = os.path.join(eegnb_data_path, experiment, 'eegnb_examples')\n",
    "\n",
    "# If dataset hasn't been downloaded yet, download it \n",
    "# if not os.path.isdir(p100_data_path):\n",
    "#     fetch_dataset(data_dir=eegnb_data_path, experiment=experiment, site='eegnb_examples')\n",
    "\n",
    "subject = 0\n",
    "session = 0\n",
    "raw = load_data(subject,session,\n",
    "                experiment=experiment, site='local', device_name='cyton',\n",
    "                data_dir = eegnb_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# Visualize the power spectrum\n",
    "# ----------------------------\n",
    "\n",
    "raw.plot_psd()\n",
    "\n",
    "###################################################################################################\n",
    "# Filtering\n",
    "# ----------------------------\n",
    "\n",
    "raw.filter(1,30, method='iir')\n",
    "raw.plot_psd(fmin=1, fmax=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################################################################################################\n",
    "# Epoching\n",
    "# ----------------------------\n",
    "\n",
    "# Create an array containing the timestamps and type of each stimulus (i.e. first or second checkerboard)\n",
    "events = find_events(raw)\n",
    "event_id = {'First checkerboard': 1, 'Second checkerboard': 2}\n",
    "\n",
    "# Create an MNE Epochs object representing all the epochs around stimulus presentation\n",
    "epochs = Epochs(raw, events=events, event_id=event_id, \n",
    "                tmin=-0.1, tmax=0.4, baseline=None,\n",
    "                reject={'eeg': 100e-6}, preload=True, \n",
    "                verbose=False, picks=[3,4,5,6,7])\n",
    "print('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\n",
    "epochs\n",
    "\n",
    "###################################################################################################\n",
    "# Epoch average\n",
    "# ----------------------------\n",
    "evoked = epochs.average()\n",
    "plot = evoked.plot(spatial_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "channel, latency, value = evoked.get_peak(tmin=0.1, tmax=0.15, mode='pos', return_amplitude=True)\n",
    "latency = int(round(latency * 1e3))  # convert to milliseconds\n",
    "value = int(round(value * 1e6))      # convert to µV\n",
    "print('Peak of {} µV at {} ms in channel {}'.format(value, latency, channel))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f62ec9868b427f8d66e4a886ef99fec3de202a265e389ba92939c6f0404d0d00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
