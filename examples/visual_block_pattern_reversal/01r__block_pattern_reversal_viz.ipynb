{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import np\n",
    "import vep_utils\n",
    "\n",
    "\"\"\"\n",
    "Pattern reversal Load and Visualize Data\n",
    "===============================\n",
    "\n",
    "This example demonstrates loading, organizing, and visualizing EP response data from the visual P100 experiment. \n",
    "\n",
    "An animation of a checkerboard reversal is shown(the checkerboard squares' colours are toggled once each half a second).\n",
    "\n",
    "The data used is the first subject and first session of the one of the eeg-notebooks P100 example datasets.\n",
    "It was recorded using an OpenBCI Ultracortex EEG headset(Mark IV) with it's last five electrodes placed in the headset's\n",
    "node locations of (PO1, Oz, PO2, P3 and P4).\n",
    "These headset node locations were used to fit around a Meta Quest 2 headset, which tilted/angled the headset backwards\n",
    "so that the real locations of the electrodes are closer to the occipital lobe - O1, Iz, O2, PO1 and PO2.\n",
    "The session consisted of using the Meta Quest 2 linked with a PC to display the checkerboard reversal animation\n",
    "for thirty seconds of continuous recording.  \n",
    "\n",
    "We first use the `fetch_datasets` to obtain a list of filenames. If these files are not already present \n",
    "in the specified data directory, they will be quickly downloaded from the cloud. \n",
    "\n",
    "After loading the data from the occiptal channels, we place it in an MNE `Epochs` object, and then an `Evoked` object to obtain\n",
    "the trial-averaged delay of the response. \n",
    "\n",
    "The final figure plotted at the end shows the P100 response EP waveform.\n",
    "\"\"\"\n",
    "\n",
    "###################################################################################################\n",
    "# Setup\n",
    "# ---------------------\n",
    "\n",
    "# Some standard pythonic imports\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MNE functions\n",
    "from mne import Epochs,find_events\n",
    "\n",
    "# EEG-Notebooks functions\n",
    "from eegnb.analysis.utils import load_data\n",
    "from vep_utils import plot_vep\n",
    "from os import path, getenv\n",
    "\n",
    "###################################################################################################\n",
    "# Load Data\n",
    "# ---------------------\n",
    "#\n",
    "# We will use the eeg-notebooks P100 example dataset\n",
    "#\n",
    "# Note that if you are running this locally, the following cell will download\n",
    "# the example dataset, if you do not already have it.\n",
    "#\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "data_dir = path.join(path.expanduser(\"~/\"), getenv('DATA_DIR'), \"data\")\n",
    "raw = load_data(subject=0,session=1,\n",
    "                experiment='block_both_eyes_pattern_reversal-mark_iv_headset', site='windows_acer_34_100hz', device_name='cyton',\n",
    "                data_dir=data_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "###################################################################################################\n",
    "# Visualize the power spectrum\n",
    "# ----------------------------\n",
    "\n",
    "raw.plot_psd()\n",
    "\n",
    "###################################################################################################\n",
    "# Filtering\n",
    "# ----------------------------\n",
    "\n",
    "raw.filter(1,30, method='fir')\n",
    "raw.plot_psd(fmin=1, fmax=30)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "###################################################################################################\n",
    "# Epoching\n",
    "# ----------------------------\n",
    "\n",
    "# Create an array containing the timestamps and which eye was presented the stimulus\n",
    "events = find_events(raw)\n",
    "event_id = {'left_eye': 1, 'right_eye': 2}\n",
    "\n",
    "# Create an MNE Epochs object representing all the epochs around stimulus presentation\n",
    "epochs = Epochs(raw, events=events, event_id=event_id,\n",
    "                tmin=-0.1, tmax=0.4, baseline=None,\n",
    "                reject={'eeg': 65e-6}, preload=True,\n",
    "                verbose=False, picks=[7])\n",
    "epochs.shift_time(-vep_utils.windows_lag())\n",
    "print('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\n",
    "epochs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "###################################################################################################\n",
    "# Epoch average\n",
    "# ----------------------------\n",
    "evoked = epochs.average()\n",
    "evoked.plot(spatial_colors=True, show=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "evoked_potentials = epochs['left_eye'].average(picks=['Oz'])\n",
    "plot_vep(evoked_potentials)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "evoked_potentials = epochs['right_eye'].average(picks=['Oz'])\n",
    "plot_vep(evoked_potentials)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "###################################################################################################\n",
    "# Compare evoked potentials by event type\n",
    "# ----------------------------\n",
    "\n",
    "# Create separate evoked responses for each event type\n",
    "evoked_left = epochs['left_eye'].average(picks=['Oz'])\n",
    "evoked_right = epochs['right_eye'].average(picks=['Oz'])\n",
    "\n",
    "# Plot both conditions on the same figure for comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Extract time points and data\n",
    "times = evoked_left.times * 1000  # Convert to milliseconds\n",
    "left_data = evoked_left.data[0] * 1e6  # Convert to microvolts\n",
    "right_data = evoked_right.data[0] * 1e6  # Convert to microvolts\n",
    "\n",
    "# Plot both conditions\n",
    "ax.plot(times, left_data, label='Left Eye', color='blue', linewidth=2)\n",
    "ax.plot(times, right_data, label='Right Eye', color='red', linewidth=2)\n",
    "\n",
    "# Add formatting\n",
    "ax.set_xlabel('Time (ms)')\n",
    "ax.set_ylabel('Amplitude (μV)')\n",
    "ax.set_title('Comparison of Evoked Potentials: Left Eye vs Right Eye')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "ax.axvline(x=0, color='black', linestyle='--', alpha=0.5, label='Stimulus Onset')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Left eye - Number of epochs: {len(epochs['left_eye'])}\")\n",
    "print(f\"Right eye - Number of epochs: {len(epochs['right_eye'])}\")\n",
    "\n",
    "# Find P100 peak for each condition (typically around 100ms)\n",
    "p100_window = (80, 120)  # milliseconds\n",
    "time_mask = (times >= p100_window[0]) & (times <= p100_window[1])\n",
    "\n",
    "left_p100_idx = np.argmax(left_data[time_mask])\n",
    "right_p100_idx = np.argmax(right_data[time_mask])\n",
    "\n",
    "left_p100_time = times[time_mask][left_p100_idx]\n",
    "left_p100_amp = left_data[time_mask][left_p100_idx]\n",
    "\n",
    "right_p100_time = times[time_mask][right_p100_idx]\n",
    "right_p100_amp = right_data[time_mask][right_p100_idx]\n",
    "\n",
    "print(f\"\\nP100 Peak Analysis:\")\n",
    "print(f\"Left eye - Peak at {left_p100_time:.1f}ms, amplitude: {left_p100_amp:.2f}μV\")\n",
    "print(f\"Right eye - Peak at {right_p100_time:.1f}ms, amplitude: {right_p100_amp:.2f}μV\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "###################################################################################################\n",
    "# Create difference wave\n",
    "# ----------------------------\n",
    "\n",
    "# Calculate the difference between conditions\n",
    "difference_data = left_data - right_data\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(times, difference_data, label='Left - Right', color='green', linewidth=2)\n",
    "ax.set_xlabel('Time (ms)')\n",
    "ax.set_ylabel('Amplitude Difference (μV)')\n",
    "ax.set_title('Difference Wave: Left Eye - Right Eye')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "ax.axvline(x=0, color='black', linestyle='--', alpha=0.5, label='Stimulus Onset')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c096d3d5a52aa51b1da1c53f69d12a5c697c7b765ecfb9c622a0b909667c12d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
